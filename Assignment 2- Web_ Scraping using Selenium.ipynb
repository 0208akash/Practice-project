{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bfc9e016",
   "metadata": {},
   "source": [
    "# WEB_SCRAPING using SELENIUM   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6597aae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\users\\anshu\\anaconda3\\lib\\site-packages (4.5.0)\n",
      "Requirement already satisfied: certifi>=2021.10.8 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from selenium) (2021.10.8)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from selenium) (0.22.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[socks]~=1.26 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from selenium) (1.26.7)\n",
      "Requirement already satisfied: idna in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.2)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.14.6)\n",
      "Requirement already satisfied: sniffio in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.0rc9 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.0.0rc9)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.2.0)\n",
      "Requirement already satisfied: sortedcontainers in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.20)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.2.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from urllib3[socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\users\\anshu\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.14.0)\n"
     ]
    }
   ],
   "source": [
    "! pip install selenium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87b10c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium\n",
    "import pandas as pd \n",
    "from selenium import webdriver\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from selenium.common.exceptions import StaleElementReferenceException,NoSuchElementException\n",
    "from selenium.webdriver.common.by import By\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61ab9c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "#downloading webdriver of same version of your browser----link('https://chromedriver.chromium.org/downloads')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44efaaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#connecting to the webdriver-------driver=webdriver.Chrome(r'Chromedriver.exe')\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Anshu\\Desktop\\assignment\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e43819f",
   "metadata": {},
   "source": [
    "###### Q1: Write a python program to scrape data for “Data Analyst” Job position in “Bangalore” location.                                                                 You have to scrape the job-title, job-location, company_name, experience_required. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Analyst” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d48d4724",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openning the naukri page an automated chrome browser\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afb5fe3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Analyst')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a77d6518",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82d59828",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click()           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "315810d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "10058988",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given tags\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')   \n",
    "\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    \n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)    \n",
    "    \n",
    "    \n",
    "    \n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)    \n",
    "    \n",
    "    \n",
    "#scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2f61e70a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 10 10 10\n"
     ]
    }
   ],
   "source": [
    "print(len(job_title),len(job_location),len(company_name),len(experience_required))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "169c8372",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Senior Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru, Chennai</td>\n",
       "      <td>Latentview</td>\n",
       "      <td>3-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Varite</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Analyst - CRM Platform</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...</td>\n",
       "      <td>Artech infosystem</td>\n",
       "      <td>1-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Jar</td>\n",
       "      <td>0-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hiring For Data Analyst (DA)/ Team Lead (TL) -...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>3-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Call For Clinical Data Analyst - Hyd/Bangalore...</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...</td>\n",
       "      <td>Cognizant</td>\n",
       "      <td>6-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Payroll Transformation Data Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Arrow Electronics</td>\n",
       "      <td>3-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Master Data Management Business Analyst</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Data Analytics and Interpretation Business Ana...</td>\n",
       "      <td>Bangalore/Bengaluru</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>6-8 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                                Senior Data Analyst   \n",
       "1                                       Data Analyst   \n",
       "2                        Data Analyst - CRM Platform   \n",
       "3                                       Data Analyst   \n",
       "4  Hiring For Data Analyst (DA)/ Team Lead (TL) -...   \n",
       "5  Call For Clinical Data Analyst - Hyd/Bangalore...   \n",
       "6                Payroll Transformation Data Analyst   \n",
       "7                Payroll Transformation Data Analyst   \n",
       "8            Master Data Management Business Analyst   \n",
       "9  Data Analytics and Interpretation Business Ana...   \n",
       "\n",
       "                                        Job_location       company_name  \\\n",
       "0                       Bangalore/Bengaluru, Chennai         Latentview   \n",
       "1                                Bangalore/Bengaluru             Varite   \n",
       "2  Bangalore/Bengaluru, Mumbai, Hyderabad/Secunde...  Artech infosystem   \n",
       "3                                Bangalore/Bengaluru                Jar   \n",
       "4  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...          Cognizant   \n",
       "5  Bangalore/Bengaluru, Kolkata, Hyderabad/Secund...          Cognizant   \n",
       "6                                Bangalore/Bengaluru  Arrow Electronics   \n",
       "7                                Bangalore/Bengaluru  Arrow Electronics   \n",
       "8                                Bangalore/Bengaluru          Accenture   \n",
       "9                                Bangalore/Bengaluru          Accenture   \n",
       "\n",
       "  Experience_required  \n",
       "0             3-6 Yrs  \n",
       "1             2-5 Yrs  \n",
       "2             1-6 Yrs  \n",
       "3             0-4 Yrs  \n",
       "4             3-8 Yrs  \n",
       "5             6-9 Yrs  \n",
       "6            5-10 Yrs  \n",
       "7             3-7 Yrs  \n",
       "8             6-8 Yrs  \n",
       "9             6-8 Yrs  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating data frame\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'company_name':company_name,'Experience_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e1becc33",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"1378a642-a8ac-4f7f-a4b2-420ce276d79c\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"c65f8206-da83-426b-a001-2c8d3eea27a2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"43387c8d-7558-4cfd-94da-2274726fae58\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"4ebf4f49-d740-472f-b6e8-64582049e619\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"88929450-74e1-4dd0-a6c9-344f51690cb2\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"fca8196e-5f75-4a3d-98fb-c67b43f389b0\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"749719a1-5d07-4876-87b5-e2acaaffb7fd\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"ffda0e14-c934-48e8-9ab4-0fa57b711b92\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"fd1036a9-bb1d-418b-8d77-9d9aed12ffac\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"d3f7c359-a572-4163-a65c-c4871dd82e84\")>]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to fetch url \n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "url[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1511c627",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/job-listings-senior-data-analyst-latentview-analytics-private-limited-chennai-bangalore-bengaluru-3-to-6-years-290922002391\n",
      "https://www.naukri.com/job-listings-data-analyst-varite-bangalore-bengaluru-2-to-5-years-011022500016\n",
      "https://www.naukri.com/job-listings-data-analyst-crm-platform-artech-infosystem-mumbai-hyderabad-secunderabad-pune-chennai-ahmedabad-bangalore-bengaluru-1-to-6-years-270922903258\n",
      "https://www.naukri.com/job-listings-data-analyst-jar-bangalore-bengaluru-0-to-4-years-290922501840\n",
      "https://www.naukri.com/job-listings-hiring-for-data-analyst-da-team-lead-tl-clinical-data-management-cognizant-technology-solutions-india-pvt-ltd-kolkata-hyderabad-secunderabad-pune-bangalore-bengaluru-mumbai-all-areas-3-to-8-years-250722007690\n",
      "https://www.naukri.com/job-listings-call-for-clinical-data-analyst-hyd-bangalore-pune-mumbai-kolkata-cognizant-technology-solutions-india-pvt-ltd-kolkata-hyderabad-secunderabad-pune-bangalore-bengaluru-mumbai-all-areas-6-to-9-years-250722005743\n",
      "https://www.naukri.com/job-listings-payroll-transformation-data-analyst-arrow-electronics-india-pvt-ltd-bangalore-bengaluru-5-to-10-years-280922502375\n",
      "https://www.naukri.com/job-listings-payroll-transformation-data-analyst-arrow-electronics-inc-bangalore-bengaluru-3-to-7-years-290922502347\n",
      "https://www.naukri.com/job-listings-master-data-management-business-analyst-accenture-solutions-pvt-ltd-bangalore-bengaluru-6-to-8-years-280922905968\n",
      "https://www.naukri.com/job-listings-data-analytics-and-interpretation-business-analyst-accenture-solutions-pvt-ltd-bangalore-bengaluru-6-to-8-years-280922905883\n"
     ]
    }
   ],
   "source": [
    "for i in url[0:10]:                #let's provide range to print top 10 url\n",
    "    print(i.get_attribute('href'))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6f20c829",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "225e12a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    titles=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for i in titles:\n",
    "        job_titles.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"fright fs14 btn-secondary br2\"]')     #to scrap data from next page\n",
    "    next_button.click()\n",
    "    time.sleep(3)        #page will sleep fpr 3 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea5de17b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "39"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "58c79644",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Senior Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst - CRM Platform',\n",
       " 'Data Analyst',\n",
       " 'Hiring For Data Analyst (DA)/ Team Lead (TL) -Clinical Data management',\n",
       " 'Call For Clinical Data Analyst - Hyd/Bangalore/Pune/Mumbai/Kolkata',\n",
       " 'Payroll Transformation Data Analyst',\n",
       " 'Payroll Transformation Data Analyst',\n",
       " 'Master Data Management Business Analyst',\n",
       " 'Data Analytics and Interpretation Business Analyst',\n",
       " 'Data analyst',\n",
       " 'HR Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst',\n",
       " 'Data Management Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst',\n",
       " 'Senior Data Analyst | Fortune500 Retail Company',\n",
       " 'Senior Data Analyst | Fortune500 Retail Company',\n",
       " 'Senior Data Analyst',\n",
       " 'Sr. SAP Hana Data Analyst',\n",
       " 'Business Execution (Data and Reporting Analyst)',\n",
       " 'Senior Data Management Analyst',\n",
       " 'Data Analyst - Python / Artificial Intelligence',\n",
       " 'Data Analyst',\n",
       " 'Data Analyst - ETL/Python/SQL',\n",
       " 'Marketing Automation Data Analyst',\n",
       " 'Data Analyst, Digital Business',\n",
       " 'Manager / Senior Manager - Data Analyst',\n",
       " 'Data Analyst ( ADF, Azure Databricks )',\n",
       " 'Executive Data Analyst',\n",
       " 'Data Analyst - FinTech',\n",
       " 'Data Analyst - FinTech',\n",
       " 'K12 Techno Services - Data Analyst - IIM/ISB/MDI/FMS/SP Jain',\n",
       " 'Manager/Senior Manager - Data Analyst',\n",
       " 'Lead Data Analyst(SQL, Python)']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52d7ec18",
   "metadata": {},
   "source": [
    "###### Q2: Write a python program to scrape data for “Data Scientist” Job position in “Bangalore” location. You have to scrape the job-title, job-location, company_name. You have to scrape first 10 jobs data.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, Companies” field and enter “Bangalore” in “enter the\n",
    "location” field.\n",
    "3. Then click the search button.\n",
    "4. Then scrape the data for the first 10 jobs results you get.\n",
    "5. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a45eeef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openning the naukri page an automated chrome browser\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "094aa550",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2d2c7838",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Bangalore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "da7c7190",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "05eca1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "986ab5d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given tags\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')   \n",
    "\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    \n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)    \n",
    "    \n",
    "    \n",
    "    \n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)    \n",
    "    \n",
    "    \n",
    "#scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2edace53",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Science Specialist</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>2-4 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Science Manager</td>\n",
       "      <td>Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...</td>\n",
       "      <td>Accenture</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Assistant Manager - Data Science</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, Pune</td>\n",
       "      <td>CitiusTech</td>\n",
       "      <td>5-9 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Hyderabad/Secunderabad, P...</td>\n",
       "      <td>Tech Mahindra</td>\n",
       "      <td>10-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai, New Delhi, Chennai</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Pune, Chennai</td>\n",
       "      <td>Wipro</td>\n",
       "      <td>8-13 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Opportunity For Senior Data Scientist/ Busines...</td>\n",
       "      <td>Bangalore/Bengaluru, Gurgaon/Gurugram, Delhi /...</td>\n",
       "      <td>PayU</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Lead ML Scientist</td>\n",
       "      <td>Bangalore/Bengaluru, Mumbai</td>\n",
       "      <td>Fractal Analytics</td>\n",
       "      <td>6-10 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0                            Data Science Specialist   \n",
       "1                               Data Science Manager   \n",
       "2  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "3                   Assistant Manager - Data Science   \n",
       "4                                     Data Scientist   \n",
       "5                              Senior Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                              Senior Data Scientist   \n",
       "8  Opportunity For Senior Data Scientist/ Busines...   \n",
       "9                                  Lead ML Scientist   \n",
       "\n",
       "                                        Job_location             company_name  \\\n",
       "0  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture   \n",
       "1  Bangalore/Bengaluru, Kolkata, Mumbai, Hyderaba...                Accenture   \n",
       "2  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...                  Mphasis   \n",
       "3                  Bangalore/Bengaluru, Mumbai, Pune               CitiusTech   \n",
       "4  Bangalore/Bengaluru, Hyderabad/Secunderabad, P...            Tech Mahindra   \n",
       "5    Bangalore/Bengaluru, Mumbai, New Delhi, Chennai  Boston Consulting Group   \n",
       "6  Bangalore/Bengaluru, New Delhi, Pune, Gurgaon/...            ZS Associates   \n",
       "7                 Bangalore/Bengaluru, Pune, Chennai                    Wipro   \n",
       "8  Bangalore/Bengaluru, Gurgaon/Gurugram, Delhi /...                     PayU   \n",
       "9                        Bangalore/Bengaluru, Mumbai        Fractal Analytics   \n",
       "\n",
       "  Experience_required  \n",
       "0             2-4 Yrs  \n",
       "1             4-7 Yrs  \n",
       "2            9-14 Yrs  \n",
       "3             5-9 Yrs  \n",
       "4           10-14 Yrs  \n",
       "5            5-10 Yrs  \n",
       "6             5-8 Yrs  \n",
       "7            8-13 Yrs  \n",
       "8             4-6 Yrs  \n",
       "9            6-10 Yrs  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating data frame\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'company_name':company_name,'Experience_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9363ff21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"5d7925f7-6543-4664-a4f0-8e65876af427\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"58b7c003-1e30-4dc1-8266-bd0751ab6908\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"45f9226e-5b3c-410e-abc8-6896a2ae0d3e\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"89d87eb6-a564-4d7d-b406-526b1bc2b718\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"a96009a8-98d3-42e1-92a3-640b4d66e8d1\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"a6181e4d-04a3-4860-a2a5-320c46608091\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"a49a2b6f-e9d9-4343-91df-db6bb7483457\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"884351cb-672b-443f-8355-1f89e1b6edd5\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"69fbd561-3b35-44b4-bd67-ec49d67f8797\")>,\n",
       " <selenium.webdriver.remote.webelement.WebElement (session=\"756c5a89dcbc4cdc278c29283854966d\", element=\"81f0c3e2-a855-4b56-9963-69f4ff6084f9\")>]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#to fetch url \n",
    "url=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "url[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee0d009e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://www.naukri.com/job-listings-data-science-specialist-accenture-solutions-pvt-ltd-kolkata-mumbai-hyderabad-secunderabad-pune-chennai-bangalore-bengaluru-2-to-4-years-230922908330\n",
      "https://www.naukri.com/job-listings-data-science-manager-accenture-solutions-pvt-ltd-kolkata-mumbai-hyderabad-secunderabad-pune-chennai-bangalore-bengaluru-4-to-7-years-230922908327\n",
      "https://www.naukri.com/job-listings-mongodb-database-administrator-maria-db-or-cassandra-mphasis-limited-hyderabad-secunderabad-pune-chennai-bangalore-bengaluru-delhi-ncr-mumbai-all-areas-9-to-14-years-210922003779\n",
      "https://www.naukri.com/job-listings-assistant-manager-data-science-citiustech-healthcare-technology-pvt-ltd-mumbai-pune-bangalore-bengaluru-5-to-9-years-010822004921\n",
      "https://www.naukri.com/job-listings-data-scientist-tech-mahindra-ltd-hyderabad-secunderabad-pune-chennai-bangalore-bengaluru-10-to-14-years-180922001173\n",
      "https://www.naukri.com/job-listings-senior-data-scientist-boston-consulting-group-mumbai-new-delhi-chennai-bangalore-bengaluru-5-to-10-years-210922500870\n",
      "https://www.naukri.com/job-listings-data-scientist-zs-associates-new-delhi-pune-gurgaon-gurugram-bangalore-bengaluru-delhi-ncr-5-to-8-years-170822001728\n",
      "https://www.naukri.com/job-listings-senior-data-scientist-wipro-limited-pune-chennai-bangalore-bengaluru-8-to-13-years-200922008774\n",
      "https://www.naukri.com/job-listings-opportunity-for-senior-data-scientist-business-analyst-with-payu-payu-payments-private-limited-gurgaon-gurugram-bangalore-bengaluru-delhi-ncr-mumbai-all-areas-4-to-6-years-210922003925\n",
      "https://www.naukri.com/job-listings-lead-ml-scientist-fractal-analytics-ltd-mumbai-bangalore-bengaluru-6-to-10-years-180822503121\n"
     ]
    }
   ],
   "source": [
    "for i in url[0:10]:                #let's provide range to print top 10 url\n",
    "    print(i.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6cb5a0ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_titles=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "27bccd38",
   "metadata": {},
   "outputs": [],
   "source": [
    "start=0\n",
    "end=2\n",
    "for page in range(start,end):\n",
    "    titles=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')\n",
    "    for i in titles:\n",
    "        job_titles.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"fright fs14 btn-secondary br2\"]')     #to scrap data from next page\n",
    "    next_button.click()\n",
    "    time.sleep(3)        #page will sleep fpr 3 seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "3ba82d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(job_titles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "da0efba1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Data Science Specialist',\n",
       " 'Data Science Manager',\n",
       " 'Mongodb Database Administrator, Maria DB or Cassandra',\n",
       " 'Assistant Manager - Data Science',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Opportunity For Senior Data Scientist/ Business Analyst with PayU',\n",
       " 'Lead ML Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist: Artificial Intelligence',\n",
       " 'Data Scientist - Computer Vision',\n",
       " 'Exciting opportunity For model monitoring/model validation role!!',\n",
       " 'Industry X - Software Engineering',\n",
       " 'Module Lead - BIDW',\n",
       " 'Data Scientist',\n",
       " 'ACN - Applied Intelligence - C4DI - Sustainability - 09',\n",
       " 'Senior Investment Risk Specialist - Data Science',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist I',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist/AIML Engineer',\n",
       " 'Senior Bioinformatics Engineer - Python Developer',\n",
       " 'Geospatial Data Engineer/Scientist',\n",
       " 'Senior Data Scientist',\n",
       " 'Data Scientist - Supply Chain',\n",
       " 'Data Science Lead - Forecasting',\n",
       " 'Data Scientist',\n",
       " 'Python Programming Language Data Science Practitioner',\n",
       " 'Data Scientist - Senior Analyst',\n",
       " 'Data Scientist',\n",
       " 'Data Scientist - A.P. Maersk',\n",
       " 'Senior Data Scientist',\n",
       " 'Deep Learning Engineer (SIPS-PS)',\n",
       " 'Data Scientist',\n",
       " 'Scientific Computing (Proactive SO)',\n",
       " 'Staff Data Scientist (Operations Research)',\n",
       " 'Principal Data Scientist',\n",
       " 'General Data Scientist']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "job_titles"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88e499af",
   "metadata": {},
   "source": [
    "###### Q3: In this question you have to scrape data using the filters available on the webpage as shown below:\n",
    "\n",
    "ASSIGNMENT 2\n",
    "\n",
    "You have to use the location and salary filter.\n",
    "You have to scrape data for “Data Scientist” designation for first 10 job results.\n",
    "You have to scrape the job-title, job-location, company name, experience required.\n",
    "The location filter to be used is “Delhi/NCR”. The salary filter to be used is “3-6” lakhs\n",
    "The task will be done as shown in the below steps:\n",
    "1. first get the webpage https://www.naukri.com/\n",
    "2. Enter “Data Scientist” in “Skill, Designations, and Companies” field.\n",
    "3. Then click the search button.\n",
    "4. Then apply the location filter and salary filter by checking the respective boxes\n",
    "5. Then scrape the data for the first 10 jobs results you get.\n",
    "6. Finally create a dataframe of the scraped data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ff082e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openning the naukri page an automated chrome browser\n",
    "driver.get('https://www.naukri.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0dca3691",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"suggestor-input\")\n",
    "designation.send_keys('Data Scientist')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6ccedc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "location=driver.find_element(By.XPATH,'/html/body/div[1]/div[6]/div/div/div[5]/div/div/div/input')\n",
    "location.send_keys('Delhi/NCR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "57ff8ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'qsbSubmit')\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38e7bc8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "salaries_list=[]\n",
    "\n",
    "salaries=driver.find_elements(By.XPATH,'//div[@class=\"fleft mt-16 mr-8 bellyFilterComp br4 bgWhite\"]')    \n",
    "for i in salaries:\n",
    "    salaries_list.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30c457e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title = []\n",
    "job_location = []\n",
    "company_name = []\n",
    "experience_required = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "af81ddbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping job title from the given tags\n",
    "title_tags=driver.find_elements(By.XPATH,'//a[@class=\"title fw500 ellipsis\"]')   \n",
    "\n",
    "for i in title_tags[0:10]:\n",
    "    title=i.text\n",
    "    job_title.append(title)\n",
    "    \n",
    "    \n",
    "#scraping job location from the given page\n",
    "location_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi location\"]')\n",
    "\n",
    "for i in location_tags[0:10]:\n",
    "    location=i.text\n",
    "    job_location.append(location)    \n",
    "    \n",
    "    \n",
    "    \n",
    "#scraping company name from the given page\n",
    "company_tags=driver.find_elements(By.XPATH,'//a[@class=\"subTitle ellipsis fleft\"]')\n",
    "\n",
    "for i in company_tags[0:10]:\n",
    "    company=i.text\n",
    "    company_name.append(company)    \n",
    "    \n",
    "    \n",
    "#scraping job experience from the given page\n",
    "experience_tags=driver.find_elements(By.XPATH,'//li[@class=\"fleft grey-text br2 placeHolderLi experience\"]')\n",
    "\n",
    "for i in experience_tags[0:10]:\n",
    "    exp=i.text\n",
    "    experience_required.append(exp)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d77453e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Job_title</th>\n",
       "      <th>Job_location</th>\n",
       "      <th>company_name</th>\n",
       "      <th>Experience_required</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Mongodb Database Administrator, Maria DB or Ca...</td>\n",
       "      <td>Delhi / NCR, Hyderabad/Secunderabad, Pune, Che...</td>\n",
       "      <td>Mphasis</td>\n",
       "      <td>9-14 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Senior Data Scientist</td>\n",
       "      <td>Mumbai, New Delhi, Chennai, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>5-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Delhi / NCR, New Delhi, Pune, Gurgaon/Gurugram...</td>\n",
       "      <td>ZS Associates</td>\n",
       "      <td>5-8 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Opportunity For Senior Data Scientist/ Busines...</td>\n",
       "      <td>Delhi / NCR, Gurgaon/Gurugram, Bangalore/Benga...</td>\n",
       "      <td>PayU</td>\n",
       "      <td>4-6 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Exciting opportunity For model monitoring/mode...</td>\n",
       "      <td>Delhi / NCR, New Delhi, Gurgaon/Gurugram, Bang...</td>\n",
       "      <td>EXL</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Gurgaon/Gurugram, Bangalore/Bengaluru</td>\n",
       "      <td>EXL</td>\n",
       "      <td>4-7 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Data Scientist</td>\n",
       "      <td>Noida, Nagpur, Bangalore/Bengaluru</td>\n",
       "      <td>GlobalLogic</td>\n",
       "      <td>8-10 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Data Science - Lead Data Scientist</td>\n",
       "      <td>Noida, Bangalore/Bengaluru</td>\n",
       "      <td>Paytm</td>\n",
       "      <td>3-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DigitalBCG GAMMA Data Scientist</td>\n",
       "      <td>New Delhi, Bangalore/Bengaluru</td>\n",
       "      <td>Boston Consulting Group</td>\n",
       "      <td>2-5 Yrs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Hiring Data Science Intern - DataTrained Educa...</td>\n",
       "      <td>Delhi / NCR, Noida, Kolkata, Hyderabad/Secunde...</td>\n",
       "      <td>DataTrained</td>\n",
       "      <td>0-2 Yrs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           Job_title  \\\n",
       "0  Mongodb Database Administrator, Maria DB or Ca...   \n",
       "1                              Senior Data Scientist   \n",
       "2                                     Data Scientist   \n",
       "3  Opportunity For Senior Data Scientist/ Busines...   \n",
       "4  Exciting opportunity For model monitoring/mode...   \n",
       "5                                     Data Scientist   \n",
       "6                                     Data Scientist   \n",
       "7                 Data Science - Lead Data Scientist   \n",
       "8                    DigitalBCG GAMMA Data Scientist   \n",
       "9  Hiring Data Science Intern - DataTrained Educa...   \n",
       "\n",
       "                                        Job_location             company_name  \\\n",
       "0  Delhi / NCR, Hyderabad/Secunderabad, Pune, Che...                  Mphasis   \n",
       "1    Mumbai, New Delhi, Chennai, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "2  Delhi / NCR, New Delhi, Pune, Gurgaon/Gurugram...            ZS Associates   \n",
       "3  Delhi / NCR, Gurgaon/Gurugram, Bangalore/Benga...                     PayU   \n",
       "4  Delhi / NCR, New Delhi, Gurgaon/Gurugram, Bang...                      EXL   \n",
       "5              Gurgaon/Gurugram, Bangalore/Bengaluru                      EXL   \n",
       "6                 Noida, Nagpur, Bangalore/Bengaluru              GlobalLogic   \n",
       "7                         Noida, Bangalore/Bengaluru                    Paytm   \n",
       "8                     New Delhi, Bangalore/Bengaluru  Boston Consulting Group   \n",
       "9  Delhi / NCR, Noida, Kolkata, Hyderabad/Secunde...              DataTrained   \n",
       "\n",
       "  Experience_required  \n",
       "0            9-14 Yrs  \n",
       "1            5-10 Yrs  \n",
       "2             5-8 Yrs  \n",
       "3             4-6 Yrs  \n",
       "4             4-7 Yrs  \n",
       "5             4-7 Yrs  \n",
       "6            8-10 Yrs  \n",
       "7             3-5 Yrs  \n",
       "8             2-5 Yrs  \n",
       "9             0-2 Yrs  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#creating data frame\n",
    "df=pd.DataFrame({'Job_title':job_title,'Job_location':job_location,'company_name':company_name,'Experience_required':experience_required})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b86651f5",
   "metadata": {},
   "source": [
    "###### Q4: Scrape data of first 100 sunglasses listings on flipkart.com. You have to scrape four attributes:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "The attributes which you have to scrape is ticked marked in the below image.\n",
    "\n",
    "To scrape the data you have to go through following steps:\n",
    "1. Go to Flipkart webpage by url : https://www.flipkart.com/\n",
    "2. Enter “sunglasses” in the search field where “search for products, brands and more” is written and\n",
    "click the search icon\n",
    "3. After that you will reach to the page having a lot of sunglasses. From this page you can scrap the\n",
    "required data as usual.\n",
    "\n",
    "ASSIGNMENT 2\n",
    "\n",
    "4. After scraping data from the first page, go to the “Next” Button at the bottom other page , then\n",
    "click on it.\n",
    "5. Now scrape data from this page as usual\n",
    "6. Repeat this until you get data for 100 sunglasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "424e9d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openning the naukri page an automated chrome browser\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "510a5415",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys('sunglasses')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "b38e178f",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a228d504",
   "metadata": {},
   "outputs": [
    {
     "ename": "NoSuchElementException",
     "evalue": "Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//a[@class=\"_1LKTO3\"]\"}\n  (Session info: chrome=106.0.5249.91)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00591ED3+2236115]\n\tOrdinal0 [0x005292F1+1807089]\n\tOrdinal0 [0x004366FD+812797]\n\tOrdinal0 [0x004655DF+1005023]\n\tOrdinal0 [0x004657CB+1005515]\n\tOrdinal0 [0x00497632+1209906]\n\tOrdinal0 [0x00481AD4+1120980]\n\tOrdinal0 [0x004959E2+1202658]\n\tOrdinal0 [0x004818A6+1120422]\n\tOrdinal0 [0x0045A73D+960317]\n\tOrdinal0 [0x0045B71F+964383]\n\tGetHandleVerifier [0x0083E7E2+2743074]\n\tGetHandleVerifier [0x008308D4+2685972]\n\tGetHandleVerifier [0x00622BAA+532202]\n\tGetHandleVerifier [0x00621990+527568]\n\tOrdinal0 [0x0053080C+1837068]\n\tOrdinal0 [0x00534CD8+1854680]\n\tOrdinal0 [0x00534DC5+1854917]\n\tOrdinal0 [0x0053ED64+1895780]\n\tBaseThreadInitThunk [0x77066A14+36]\n\tRtlInitializeExceptionChain [0x77E5A9FF+143]\n\tRtlInitializeExceptionChain [0x77E5A9CA+90]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_10172/81428798.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mbrand\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mBrand\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m     \u001b[0mnext_button\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdriver\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfind_element\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mBy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mXPATH\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'//a[@class=\"_1LKTO3\"]'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m     \u001b[0mnext_button\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclick\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mfind_element\u001b[1;34m(self, by, value)\u001b[0m\n\u001b[0;32m    854\u001b[0m             \u001b[0mvalue\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'[name=\"%s\"]'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    855\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 856\u001b[1;33m         return self.execute(Command.FIND_ELEMENT, {\n\u001b[0m\u001b[0;32m    857\u001b[0m             \u001b[1;34m'using'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mby\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    858\u001b[0m             'value': value})['value']\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\webdriver.py\u001b[0m in \u001b[0;36mexecute\u001b[1;34m(self, driver_command, params)\u001b[0m\n\u001b[0;32m    427\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcommand_executor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdriver_command\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    428\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 429\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merror_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcheck_response\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    430\u001b[0m             response['value'] = self._unwrap_value(\n\u001b[0;32m    431\u001b[0m                 response.get('value', None))\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\selenium\\webdriver\\remote\\errorhandler.py\u001b[0m in \u001b[0;36mcheck_response\u001b[1;34m(self, response)\u001b[0m\n\u001b[0;32m    241\u001b[0m                 \u001b[0malert_text\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'alert'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'text'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malert_text\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[call-arg]  # mypy is not smart enough here\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 243\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mexception_class\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstacktrace\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNoSuchElementException\u001b[0m: Message: no such element: Unable to locate element: {\"method\":\"xpath\",\"selector\":\"//a[@class=\"_1LKTO3\"]\"}\n  (Session info: chrome=106.0.5249.91)\nStacktrace:\nBacktrace:\n\tOrdinal0 [0x00591ED3+2236115]\n\tOrdinal0 [0x005292F1+1807089]\n\tOrdinal0 [0x004366FD+812797]\n\tOrdinal0 [0x004655DF+1005023]\n\tOrdinal0 [0x004657CB+1005515]\n\tOrdinal0 [0x00497632+1209906]\n\tOrdinal0 [0x00481AD4+1120980]\n\tOrdinal0 [0x004959E2+1202658]\n\tOrdinal0 [0x004818A6+1120422]\n\tOrdinal0 [0x0045A73D+960317]\n\tOrdinal0 [0x0045B71F+964383]\n\tGetHandleVerifier [0x0083E7E2+2743074]\n\tGetHandleVerifier [0x008308D4+2685972]\n\tGetHandleVerifier [0x00622BAA+532202]\n\tGetHandleVerifier [0x00621990+527568]\n\tOrdinal0 [0x0053080C+1837068]\n\tOrdinal0 [0x00534CD8+1854680]\n\tOrdinal0 [0x00534DC5+1854917]\n\tOrdinal0 [0x0053ED64+1895780]\n\tBaseThreadInitThunk [0x77066A14+36]\n\tRtlInitializeExceptionChain [0x77E5A9FF+143]\n\tRtlInitializeExceptionChain [0x77E5A9CA+90]\n"
     ]
    }
   ],
   "source": [
    "for page in(0,3):\n",
    "    Brand = []  #empty list\n",
    "    brand=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')\n",
    "    for i in brand:\n",
    "        Brand.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)\n",
    "    Brand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6996877",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in(0,3):\n",
    "    Product_Description = []  #empty list\n",
    "    pd_tag=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in pd_tag:\n",
    "        Product_Description.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12ec6638",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in(0,3):\n",
    "    Price = []  #empty list\n",
    "    pr=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in pr:\n",
    "        Price.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6169429",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in(0,3):\n",
    "    Discount = []  #empty list\n",
    "    dis=driver.find_elements(By.XPATH,'//div[@class=\"_3Ay6Sb\"]')\n",
    "    for i in dis:\n",
    "        Discount.append(i.text)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    next_button.click()\n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10615ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating data frame\n",
    "Sunglasses=pd.DataFrame({})\n",
    "\n",
    "Sunglasses['Product_Description']=Product_Description[:100]\n",
    "Sunglasses['Price']=Price[:100]\n",
    "Sunglasses['Discount']=Discount[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67a5f81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping brand_name from the given tags\n",
    "start=0\n",
    "end=5\n",
    "for page in range(start,end):\n",
    "    brand_name=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"]')   \n",
    "    for i in brand_name[0:100]:\n",
    "        brand=i.text\n",
    "        brand_name.append(brand)\n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')      ## to scrap data from the next pAGE\n",
    "    next_button.click()\n",
    "    time.sleep(3)      #page will sleep for 5 seconds\n",
    "    \n",
    "#scraping Product_description\n",
    "start=0\n",
    "end=5\n",
    "for page in range(start,end):\n",
    "    Product_description=driver.find_elements(By.XPATH,'//a[@class=\"IRpwTa\"]')\n",
    "    for i in Product_description[0:100]:\n",
    "        desc=i.text\n",
    "        Product_description.append(desc)  \n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')      ## to scrap data from the next pAGE\n",
    "    next_button.click()\n",
    "    time.sleep(3)      #page will sleep for 5 seconds\n",
    "    \n",
    "    \n",
    "    \n",
    "#scraping Price\n",
    "start=0\n",
    "end=5\n",
    "for page in range(start,end):\n",
    "    Price=driver.find_elements(By.XPATH,'//div[@class=\"_30jeq3\"]')\n",
    "    for i in Price[0:100]:\n",
    "        price=i.text\n",
    "        Price.append(price) \n",
    "    next_button=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')      ## to scrap data from the next pAGE\n",
    "    next_button.click()\n",
    "    time.sleep(3)      #page will sleep for 5 seconds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee8b66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating data frame\n",
    "df=pd.DataFrame({'BRAND':brand_name,'Product_Description':Product_description,'PRICE':Price})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44703449",
   "metadata": {},
   "source": [
    "###### Q5: Scrape 100 reviews data from flipkart.com for iphone11 phone.\n",
    "This task will be done in following steps:\n",
    "1. First get the webpage https://www.flipkart.com/\n",
    "2. Enter “iphone 11” in “Search” field .\n",
    "3. Then click the search button.\n",
    "You will reach to the below shown webpage .\n",
    "As shown in the above page you have to scrape the tick marked attributes.These are:\n",
    "1. Rating\n",
    "2. Review summary\n",
    "3. Full review\n",
    "4. You have to scrape this data for first 100 reviews.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be78ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openning the naukri page an automated chrome browser\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c76c50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys('iphone 11')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17e746a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,'L0Z3Pu')\n",
    "search.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f60cef7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data\n",
    "Rating=[]      #creating empty lists\n",
    "Review_summary=[]\n",
    "Full_review=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570b6c60",
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in range(1,12):\n",
    "    rating=driver.find_elements(By.XPATH,'//div[@class=\"_3LWZlK _1BLPMq\"]')   \n",
    "    for i in rating[0:100]:\n",
    "        rt=i.text \n",
    "        rating.append(rt)\n",
    "    \n",
    "    review=driver.find_elements(By.XPATH,'//p[@class=\"_2-N8zT\"]')   \n",
    "\n",
    "    for j in review[0:100]:\n",
    "        rev=j.text\n",
    "        review.append(rev)\n",
    "        \n",
    "    full_review=driver.find_elements(By.XPATH,'//div[@class=\"t-ZTKy\"]')   \n",
    "\n",
    "    for k in full_review[0:100]:\n",
    "        frev=k.text\n",
    "        review.append(frev)  \n",
    "    next_page=driver.find_element(By.XPATH,'//a[@class=\"_1LKTO3\"]')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "155fd8fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.DataFrame({'RATING_name':rating,'REVIEW_Summary':review,'FULL_REVIEW':full_review})\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1175fd",
   "metadata": {},
   "source": [
    "###### Q6: Scrape data for first 100 sneakers you find when you visit flipkart.com and search for “sneakers” in the\n",
    "search field.\n",
    "You have to scrape 4 attributes of each sneaker:\n",
    "1. Brand\n",
    "2. Product Description\n",
    "3. Price\n",
    "As shown in the below image, you have to scrape the tick marked attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55d34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#openning the naukri page an automated chrome browser\n",
    "driver.get('https://www.flipkart.com/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d694bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#entering designation and location as required in the question\n",
    "designation=driver.find_element(By.CLASS_NAME,\"_3704LK\")\n",
    "designation.send_keys('sneakers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc3a39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "search=driver.find_element(By.CLASS_NAME,\"L0Z3Pu\")\n",
    "search.click() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa1ff1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating the empty lists\n",
    "Brand=[]\n",
    "Product_Description=[]\n",
    "Price=[]\n",
    "Discount=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89277d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "#scraping data\n",
    "brand=driver.find_elements(By.XPATH,'//div[@class=\"_2WkVRV\"')   \n",
    "\n",
    "for i in brand[0:10]:\n",
    "    brnd=i.text\n",
    "    brand.append(brnd)\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecc7af80",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
